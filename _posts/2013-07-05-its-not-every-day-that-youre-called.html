---
title: It's not every day that you're called an idiot by Nassim Taleb
comments: true
tags:
- Psychology
- Behavioural Economics
- Uncertainty
thumbnail: http://2.bp.blogspot.com/-v6bHplElL6s/UdaeidWt6OI/AAAAAAAAAUM/LOK6p3FlGkU/s72-c/perceivedrisk.jpg
blogger_orig_url: http://stickmanscorral.blogspot.com/2013/07/its-not-every-day-that-youre-called.html
---

Or a "bloggist" for that matter.<br /><br /><a href="https://twitter.com/nntaleb/status/352794142960656384" target="_blank">Here</a> and <a href="https://twitter.com/nntaleb/status/352792251681878016" target="_blank">here</a>.<br /><br />To be fair, Taleb has charged that many minds superior to my own are beset by idiocy, so I'm in reasonable company. More seriously, he did at least tone down his bombast when I pointed out that he had misunderstood what I was asking.<br /><br />The background <a href="{{ site.baseurl }}{% post_url 2013-02-07-a-question-for-nassim-taleb-fans %}" target="_blank">is this post</a>, where I wondered (quite respectful like!) what Taleb made of the research that shows people have a tendency to <i>over</i>estimate the likelihood of low-probability events if they were framed in highly dramatic terms. This seemed to run counter to a recurring theme in his writings, which is that people are blind to "black swans"... basically that they consistently underestimate low-prob, high impact events.<br /><br />Taleb pointed me towards a <a href="http://t.co/jAGSyVixuD" target="_blank">short paper</a> on "binary" (up vs down) versus "vanilla" (+500 vs +5,000,000 vs -5,000,000) outcomes, which was supposed to refute the relevance of such studies. However, I remain rather unconvinced. Consider the key figure in my previous post:<br /><br /><table align="center" cellpadding="0" cellspacing="0" class="tr-caption-container" style="margin-left: auto; margin-right: auto; text-align: center;"><tbody><tr><td style="text-align: center;"><a href="http://2.bp.blogspot.com/-v6bHplElL6s/UdaeidWt6OI/AAAAAAAAAUM/LOK6p3FlGkU/s400/perceivedrisk.jpg" imageanchor="1" style="margin-left: auto; margin-right: auto;"><img border="0" src="http://2.bp.blogspot.com/-v6bHplElL6s/UdaeidWt6OI/AAAAAAAAAUM/LOK6p3FlGkU/s1600/perceivedrisk.jpg" /></a></td></tr><tr><td class="tr-caption" style="text-align: center;">Perceived versus actual fatalities. Adapted from Lichtenstein <i>et al</i>. (1978).</td></tr></tbody></table><br />As I wrote back then: <span>What we see here is that people have a clear tendency to overstate &mdash; by an order of several magnitudes &mdash; the relative likelihood of death arising due to "unusual and sensational" causes (tornadoes, floods, etc). The opposite is true for more mundane causes of death like degenerative disease (diabetes, stomach cancer, etc).</span><br /><br />Now, I certainly agree with Taleb that it is important to distinguish between between binary and continuous outcomes. Asking whether a stock will go up/down is a much less interesting (and less complex) question to ask than whether it will go up/down by a certain amount. You are clearly not comparing apples with apples if you say that a stock will go up by 5% or 500%. In short, binary and continuous ("vanilla") outcomes are incommensurable in terms of evaluating payoffs.<br /><br />However, the studies that I linked to are interesting <i>exactly because</i> they are comparing the *same* outcome (i.e. death). It makes no sense to say that death by tornado equals five times death by stroke. They are obviously equivalent. The "payoff" is thus the same because the outcome is the same. Further, I'm not claiming that the insights from these particular studies are fully generalisable to all other low probability, high-impact outcomes (especially those in finance). Yet they do show that underestimation of black swan events is hardly a universal phenomenon either... In fact, people here are shown to rely on heuristics that lead them to a diametrically opposite conclusion! I was ultimately interested in hearing from Taleb whether he thinks these heuristics are efficient or not. I didn't get an answer unfortunately, so I guess we'll have to judge for ourselves.<br /><br />A final observation is that I disagree with <a href="http://papers.ssrn.com/sol3/papers.cfm?abstract_id=2284964" target="_blank">the paper's</a> assertion that "binary is limited to probability". (In other words, that binary outcomes say nothing about the size of a payoff.) This is certainly true in many cases &mdash; again, especially in finance &mdash; but not always. In some instances, binary outcomes imply payoffs directly. The obvious example is the one that we have been discussing in this very post, i.e. death. Indeed, I would think that Taleb probably agrees with me, given that one of his favourite analogies is that of a turkey being fattened up in preparation for Thanksgiving.<br /><br /><table align="center" cellpadding="0" cellspacing="0" class="tr-caption-container" style="margin-left: auto; margin-right: auto; text-align: center;"><tbody><tr><td style="text-align: center;"><img src="http://www.edge.org/3rd_culture/taleb08/images/image002.png" style="margin-left: auto; margin-right: auto;" /></td></tr><tr><td class="tr-caption" style="text-align: center;">What Taleb calls his "classical metaphor". A turkey on his way to becoming dinner. (<a href="http://edge.org/conversation/the-fourth-quadrant-a-map-of-the-limits-of-statistics" target="_blank">Source</a>)</td></tr></tbody></table><br />With apologies to <a href="http://en.wikipedia.org/wiki/Dead_Parrot_sketch" target="_blank">Monty Python</a>, you might say that the prospect of becoming an ex-turkey implies a very obvious payoff indeed.<br /><br /><b>UPDATE:</b> Andrei Shleifer <a href="{{ site.baseurl }}{% post_url 2013-11-14-mcdermott-and-shleifer-double-team %}" target="_blank">agrees</a>.